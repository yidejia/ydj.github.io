{"meta":{"title":"伊的家技术博客","subtitle":"自驱自律自组织","description":"伊的家","author":"伊的家技术部","url":"https://yidejia.github.io"},"pages":[{"title":"categories","date":"2016-11-01T09:56:12.000Z","updated":"2016-11-04T07:01:10.000Z","comments":false,"path":"categories/index.html","permalink":"https://yidejia.github.io/categories/index.html","excerpt":"","text":""},{"title":"categories","date":"2016-11-01T09:56:12.000Z","updated":"2016-11-04T07:01:10.000Z","comments":false,"path":"tags/index.html","permalink":"https://yidejia.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"什么是计算机内存？","slug":"caokun_memory","date":"2016-11-04T08:21:55.000Z","updated":"2016-11-04T08:21:04.000Z","comments":true,"path":"2016/11/04/caokun_memory/","link":"","permalink":"https://yidejia.github.io/2016/11/04/caokun_memory/","excerpt":"","text":"计算机存储体系先来看这张计算机存储体系结构图。 从上图可以看到，越在上面的访问速度越快，但是容量越小，今天要说的就是内存那个环节。 内存是什么 内存是可以记录二进制数据一种器件，它是连续的结构，可以随机读写，断电会丢失数据，所有程序必须从磁盘加载到内存中才能运行。 硬件实现简单说一下，二进制数据的每一个bit由一种叫电容器的元件记录，有电子表示1，没电子表示0。可以想象一个4G的内存条，上面有34359738368个这样微小的元件。电容容易丢失电子，所以每64ms必须对内存充电（内存刷新），充电过程中，不允许CPU访问数据，会造成任务延迟。 内存空间管理策略 上面说了内存是一个连续的线性结构，一个4G的内存有很多个电容，把他们线性排在一起，那么就有0~34359738367个可以存bit的空位，计算机一般把8个bit合成一个byte存放，那么就有0~4294967295个byte，写成16进制就是 0x0 ~ 0xFFFFFFFF个地址，这个就是内存地址了，每个地址里面可以取出一个字节的数据。 现在有0xFFFFFFFF个地址，人们是怎么利用操作系统去管理和分配这些地址给程序使用的呢？ 为了方便说明问题，我把内存地址用10进制表示，转成16进制也是一样的，16进制不太方便人脑计算。我不用4G的内存讲，因为太多了，用0到99的内存空间即可说明问题。我尽量用通俗的语言说明问题，没有很复杂的概念，复杂的概念请翻看《操作系统原理》。 虚拟内存地址与实际物理地址 在说怎么管理内存之前，先要说一下虚拟内存地址，最开始人们在程序直接使用实际的物理地址，如下图：假设程序a第一次启动被装载在1的位置，第二次启动装载在31的位置。程序a中有段代码 jmp 3，想去执行3那里的目标代码。显然第一次jmp是对的，但第二次操作系统把装在了31的位置，显然目标代码应该是33了，就应该把程序改为jmp 33，否则就出错了。这就是直接使用物理地址的弊端，每次启动都要重新改代码，或者把所有跳转的地方都+30，很麻烦。所以现代程序都不直接使用物理地址，而是用了虚拟地址，如下图使用了虚拟地址后，每个程序就认为自己是从0地址开始的就好了，不管加载到哪个地方，都不用在修改代码，通过一个段表就可以把虚拟地址转为实际的物理地址。 在编译器debug中可以看到 0x0012fee8 这些都是虚拟地址，物理地址操作系统不允许直接访问了。 段式管理 最开始人们用段式管理，但是段式管理会产生内存碎片，过程如下图当程序c要加载进内存的时候，程序b前面的空间不够了，只能从b后面分配，于是b前面的空间就不能给c利用，成为了内存碎片。 操作系统为了避免这种情况，充分利用内存空间，当内存不够的时候，会采取内存紧缩，就是把所有程序都往左边挪动，全部紧紧的排在一起，但是实际中对4GB的内存空间进行紧缩的时候，需要5秒左右的时间，计算机经常卡机5秒你能忍？ 程序c分配内存的策略有首先适配法，最佳适配法等方法，考虑到篇幅就不展开讲了，我上面用的就是首先适配法，从左到右首次找到一个合适位置就分配。 页式管理 由于段式管理的缺点（外部碎片，内存紧缩），人们后来发明了页式管理，通俗来说，页式管理就是把一定大小的物理空间当做一个页框，整个内存中就有很多个这样的页框，比如0到99的内存空间，按10个字节为一个页框，那么整个内存就分成了10页框，0到9是第0个页框，如下图：按照页式管理划分空间后，一个程序用一个页框要么使用页框全部空间，要么不能使用，不能说只用一点点，如果一个程序用不上那么多空间，也必须拿完，于是段式管理的外部碎片和内存紧缩的问题被解决了，提高了内存利用率，但是又产生内存内部碎片。 程序的页和页框的大小是一样的，页框大小如何确定？如果页框太大，产生的内部碎片也大，如果页框太小，导致页表变大，查找速度降低。例如4GB的内存，按照4KB分为一页，4GB / 4KB = 1048576项，查找起来自然慢了。 虚拟地址到物理地址转换过程上图还有个在不在位，这个位表示如果程序的页在页框中，那么直接转换，如果不在页框中，那么引发一个缺页中断，操作系统去磁盘上把缺失的页加载进内存，然后程序才继续往下运行。这里有个重点，运行中的程序不一定全部在内存中，也有可能在磁盘上，在磁盘上的那部分叫做虚拟内存！，那究竟程序的哪些页面在内存中，哪些页面在磁盘上，这里就涉及到页面置换算法 页面置换算法一个程序的部分页面在内存中，部分页面在磁盘上，究竟怎么确定这些页面？我选几个来说 先进先出（FIFO）最简单的，最先进来的，就最先淘汰出去。缺点：有些频繁访问的页面也可能淘汰出去。 二次机会（SC）最先进来的页面不一定最先出去，如果这个页面的访问标志是1，那么把它置为0，再给它一次机会，如果页面访问标志0，那么才置换出去。 最近未使用（NRU）每个页面有两个标志位，标记是否访问，是否修改，显然那么没有怎么访问，没有修改的页面会被淘汰出去。 最近最少使用（LRU）这个也很好理解，每个页面有个计数器，访问一次就加1，显然把访问次数很少的那些优先淘汰。 此外还有老化算法，工作集算法，等等，限于篇幅（其实是我写累了）就不详细叙说了，我已经写了个实验代码，在这里可以看到。 段页式管理最后是段页式管理，结合了段式页式的优缺点，把程序先分段，在每个段内再分页，来管理内存，windows操作系统就是用这个方法管理的，当然实际中更加复杂，绝对没有我说的这么简单，我只是通俗的说清原理，详情请看《操作系统原理》","categories":[{"name":"移动端","slug":"移动端","permalink":"https://yidejia.github.io/categories/移动端/"}],"tags":[{"name":"曹堃","slug":"曹堃","permalink":"https://yidejia.github.io/tags/曹堃/"},{"name":"内存","slug":"内存","permalink":"https://yidejia.github.io/tags/内存/"}],"keywords":[{"name":"移动端","slug":"移动端","permalink":"https://yidejia.github.io/categories/移动端/"}]},{"title":"iOS - 仿UC浏览器首页下拉动画及实现分析","slug":"caokun_UC_animation","date":"2016-11-04T08:12:55.000Z","updated":"2016-11-04T08:58:47.000Z","comments":true,"path":"2016/11/04/caokun_UC_animation/","link":"","permalink":"https://yidejia.github.io/2016/11/04/caokun_UC_animation/","excerpt":"","text":"动画效果 经常用UC看到首页有这么一个动画，就仿造写了一下。 实现分析1.画曲线的动画这个一眼看去就想到用贝塞尔曲线画，来看贝塞尔曲线方法，给出两个定点，和一个控制点就可以画。1CGContextAddQuadCurveToPoint(context, 控制点x, 控制点y, 目标点x, 目标点y); 于是按照下图，两个黄色的点是定点，绿色的是控制点，于是画出了这样的图。 看左边的图，中间有大片空白，看起来很浪费屏幕空间，用户体验不太好，于是想着怎么让贝塞尔曲线过某个定点，比如让曲线过绿色的定点，而不是把控制点设在绿色的位置。 重诉一下，现有的方法是给出两个定点和一个控制点，能画一条曲线。现在是要，已知两个定点，和过另外一个定点D，画一条曲线。 我现在想让这条曲线过绿色的点，就像下图那样，求控制点坐标是多少？ 看下图，求出控制点坐标的过程 由上图就得出了控制点的坐标，然后就可以画出“图3”的样子了，实际中我觉得图3贴太紧了，也不美观，于是 yc 乘了个0.6的系数，即 yc = 0.6 * yc，就看起来比较顺眼了。 2.页面结构页面结构大概是这样，底下的 tableView 铺满整个 view，然后蓝色的headerView 加在 tableView 的上面，不是加 tableView.tableHeaderView 上面哦，至于为什么你加加看就知道了。会跟着 tableview 动 3.不规则事件点击，事件穿透headerView 上有一个头像，是可以点击的，其他地方的点击事件要传给底下的 tableView 也叫事件穿透，通过修改 hitTest 可以实现1- (UIView *)hitTest:(CGPoint)point withEvent:(UIEvent *)event; hitTest 主要用来做事件分发的，可以实现不规则点击，它在整个 view 结构上是递归的，深度优先的，今天不讲算法，因为 hitTest 太厉害，不规则点击用 pointInside 函数就够了。1- (BOOL)pointInside:(CGPoint)point withEvent:(UIEvent *)event; 这个函数会被 hitTest 调用，返回 false 表示点击的不是自己，返回 true 表示点击的是自己。那么，我只要判断点击的 point 在不在头像的那个圆圈里面就可以了，就是判断点在不在圆内，高中讲过了，point 到圆心的距离小于半径就表示在了，那么返回 true 就行。具体的还是看代码吧。如果有多个控件，需要自己确定每个控件的点击区域。 最后还是上个代码 下载地址，下载慢慢看吧。 4.后期改进写完这个博客突然想到一个还要改的地方，就是当用户手指松开的时候，scrollViewWillEndDragging，这个方法内判断一下，contentOffset.y 值，如果超过多少值，那么自动回调一个 block，可实现下拉刷新。","categories":[{"name":"移动端","slug":"移动端","permalink":"https://yidejia.github.io/categories/移动端/"}],"tags":[{"name":"曹堃","slug":"曹堃","permalink":"https://yidejia.github.io/tags/曹堃/"},{"name":"动画","slug":"动画","permalink":"https://yidejia.github.io/tags/动画/"},{"name":"iOS","slug":"iOS","permalink":"https://yidejia.github.io/tags/iOS/"}],"keywords":[{"name":"移动端","slug":"移动端","permalink":"https://yidejia.github.io/categories/移动端/"}]},{"title":"通俗讲解股票类app - TCP网络通信层设计","slug":"caokun_socket","date":"2016-11-04T07:12:55.000Z","updated":"2016-11-04T07:48:16.000Z","comments":true,"path":"2016/11/04/caokun_socket/","link":"","permalink":"https://yidejia.github.io/2016/11/04/caokun_socket/","excerpt":"","text":"场景要做的产品 — 炒股app 数据量大：5000多支股票，每支股票有分时，分笔数据，画一条k线，可能要500条分时数据，甚至更多。 实时性：股价每分每秒都在变化，一分钟产生很多条数据，用户要看到最新的信息，真的是一秒钟上下几十万啊。 服务器主动推：股票预警等等一些重要消息，需要服务器实时推送，保证客户端100%收到，收不到可能造成客户资金损失。 由于这些场景因素，股票的数据不能通过HTTP协议来传输了，只能走TCP协议了，当然一些个人信息什么的还是走HTTP的。 技术细节实现1.数据量比较大，一次请求可能返回几百条数据到移动端，对数据要进行压缩，这里采用了 google 的 Protocol Buffer 数据传输格式，因为它对象序列化速度快，压缩率高 (ps: http 一般用 json, xml)。 2.实时性与主动推：服务器与客户端之间维护一条 tcp 长连接，避免每次3次握手，4次挥手，和产生一堆 time_wait 状态的 socket 占用资源。走tcp协议需要自己维护一些状态掉线重连，移动端网络情况复杂，有3G，4G，wifi，socket 经常断开，它断了要自动连上，并且还要对应用层透明！不能让应用层感知到！连上后数据接着之前断开的地方发送，不能有影响。自动登录，这个是掉线重连后要做的一个操作，不登录拿不到股票数据。登录后接着做一个消息同步，看看有没有新消息。 3.客户端100%收到（可靠性）：除了 tcp 超时重传和3次ack回应保证了可靠传输之外，我们在app里也实现了一套应用层的ack机制，服务器保存了一组消息，每个消息有个seq号，一个消息推给客户端后，客户端拿到消息的seq，要发ack请求回应服务器这个消息，然后下次服务器才不会推给你，不然的话，下次服务器还是会推给你的。掉线重连，重登录后会同步一次你订阅过的消息，把上次没收到的，或者丢包的消息再同步过来。 4.客户端的负载均衡，这个一般在服务器做，但后台那边说防止ip封锁，还有某些服务器不能在全国访问到，所以把负载均衡放在客户端做了，app启动拉取服务器列表，然后多线程并发发送测速包，得到每个服务器延迟和负载，然后选个最优的服务器连上即可，延迟可以理解为路有多长，负载可以理解为路上拥堵情况，显然最短的路不一定是最快的，它可能很堵。 根据以上因素，我设计了一套TCP层的网络请求逻辑，应用层只管发请求就好了，我只告诉你有没有结果，上面的细节全部屏蔽在底层，对应用层透明！ 12345678// 应用层发一个 tcp 请求的代码例子，支持多线程循环发：[[TCPAPI instance] requestStockInfoWithcompletion:^(id response, NSString *error) &#123; if (error == nil) &#123; NSLog(@&quot;成功：%@&quot;, (NSArray *)response); &#125; else &#123; NSLog(@&quot;失败：%@&quot;, error); &#125;&#125;]; 测试：我用一条线程以每隔 0.1 秒的速度循环发送请求，然后模拟断网，网络差，被服务器踢下线等等情况，程序工作正常，一旦有网络，数据就会成功返回。 整个app网络层的请求逻辑图：我有个 tcp 请求同步队列接收应用层来的请求，有句话叫做”we cannot send directly, so queue it”，然后一个请求走完图中的逻辑，下一个请求接着走，每一个请求有一个定时器，超时就回调一个失败结果给应用层，有张映射表保存请求和回调之间的映射。然后还一个socket发送队列，真正去发送数据的队列，socket接收队列就不用说了吧，把接收到的数据通过pb协议反序列化得到pb对象的，这里有个 tcp 分片机制导致的 tcp 粘包问题，就是 socket 返回一段二进制数据不一定刚好就是一个对象的全部数据，可能少可能多，要自己判断，拆包的时候注意下就好了。得到 pb 对象，把这个结果回调给应用层，整个流程就走完了。 图片可能太大，可以到这里下载来看。","categories":[{"name":"移动端","slug":"移动端","permalink":"https://yidejia.github.io/categories/移动端/"}],"tags":[{"name":"曹堃","slug":"曹堃","permalink":"https://yidejia.github.io/tags/曹堃/"},{"name":"socket","slug":"socket","permalink":"https://yidejia.github.io/tags/socket/"}],"keywords":[{"name":"移动端","slug":"移动端","permalink":"https://yidejia.github.io/categories/移动端/"}]},{"title":"iOS - 接入WebSocket记录 + 一些个人经验","slug":"caokun_websocket","date":"2016-11-04T06:12:55.000Z","updated":"2016-11-04T08:59:10.000Z","comments":true,"path":"2016/11/04/caokun_websocket/","link":"","permalink":"https://yidejia.github.io/2016/11/04/caokun_websocket/","excerpt":"","text":"闲扯WebSocket 以前没用过，之前写过一篇博客是基于原生socket的（查看）比较复杂，慎入。今天另外一个APP需要接websocket了，然后便找到了facebook的 SocketRocket 框架，然后用了一天时间接上了，完成了掉线自动重连，自动重登录，心跳等等功能，用法比原生socket简单（原生socket基于TCP/UDP协议）。 为什么用 WebSocket因为APP里面有个聊天功能，需要服务器主动推数据到APP。HTTP 通信方式只能由客户端主动拉取，服务器不能主动推给客户端，如果有实时的消息，要立刻通知客户端就麻烦了，要么客户端每隔几秒钟发一次请求，看看有没有新数据，这种方式想想都知道耗流量电量。还一种方式就是走TCP/UDP协议服务器主动推给你，这种方式省流量。还有就是用websocket，websocket是h5里面的东西，h5我不太会，反正它比原生socket用法简单。 用法用 SocketRocket 框架，记住几个代理方法就好了，很简单。 1.创建和设置代理对象123456SRWebSocket *socket = [[SRWebSocket alloc] initWithURLRequest:[NSURLRequest requestWithURL:[NSURL URLWithString:@&quot;http://ip地址:端口&quot;]];socket.delegate = self; // 实现这个 SRWebSocketDelegate 协议啊[socket open]; // open 就是直接连接了 2.连接成功会调用这个代理方法123- (void)webSocketDidOpen:(SRWebSocket *)webSocket &#123; NSLog(@&quot;连接成功，可以立刻登录你公司后台的服务器了，还有开启心跳&quot;);&#125; 3.连接失败会调用这个方法，看 NSLog 里面的东西1234567- (void)webSocket:(SRWebSocket *)webSocket didFailWithError:(NSError *)error &#123; NSLog(@&quot;连接失败，这里可以实现掉线自动重连，要注意以下几点&quot;); NSLog(@&quot;1.判断当前网络环境，如果断网了就不要连了，等待网络到来，在发起重连&quot;);NSLog(@&quot;2.判断调用层是否需要连接，例如用户都没在聊天界面，连接上去浪费流量&quot;);NSLog(@&quot;3.连接次数限制，如果连接失败了，重试10次左右就可以了，不然就死循环了。或者每隔1，2，4，8，10，10秒重连...f(x) = f(x-1) * 2, (x&lt;5) f(x)=10, (x&gt;=5)&quot;);&#125; 4.连接关闭调用这个方法，注意连接关闭不是连接断开，关闭是 [socket close] 客户端主动关闭，断开可能是断网了，被动断开的。123- (void)webSocket:(SRWebSocket *)webSocket didCloseWithCode:(NSInteger)code reason:(NSString *)reason wasClean:(BOOL)wasClean &#123; NSLog(@&quot;连接断开，清空socket对象，清空该清空的东西，还有关闭心跳！&quot;);&#125; 5.收到服务器发来的数据会调用这个方法123456- (void)webSocket:(SRWebSocket *)webSocket didReceiveMessage:(id)message &#123;NSLog(@&quot;收到数据了，注意 message 是 id 类型的，学过C语言的都知道，id 是 (void *) void* 就厉害了，二进制数据都可以指着，不详细解释 void* 了&quot;);NSLog(@&quot;我这后台约定的 message 是 json 格式数据收到数据，就按格式解析吧，然后把数据发给调用层&quot;);&#125; 6.向服务器发送数据发送的时候可能断网，可能socket还在连接，要判断一些情况，写在下面了发送逻辑是，我有一个 socketQueue 的串行队列，发送请求会加到这个队列里，然后一个一个发出去，如果掉线了，重连连上后继续发送，对调用层透明，调用层不需要知道网络断开了。 12345678910111213141516171819202122232425262728- (void)sendData:(id)data &#123; WEAKSELF(ws); dispatch_async(self.socketQueue, ^&#123; if (ws.socket != nil) &#123;// 只有 SR_OPEN 开启状态才能调 send 方法啊，不然要崩 if (ws.socket.readyState == SR_OPEN) &#123; [ws.socket send:data]; // 发送数据 &#125; else if (ws.socket.readyState == SR_CONNECTING) &#123; NSLog(@&quot;正在连接中，重连后其他方法会去自动同步数据&quot;);// 每隔2秒检测一次 socket.readyState 状态，检测 10 次左右// 只要有一次状态是 SR_OPEN 的就调用 [ws.socket send:data] 发送数据// 如果 10 次都还是没连上的，那这个发送请求就丢失了，这种情况是服务器的问题了，小概率的// 代码有点长，我就写个逻辑在这里好了 &#125; else if (ws.socket.readyState == SR_CLOSING || ws.socket.readyState == SR_CLOSED) &#123;// websocket 断开了，调用 reConnect 方法重连 [ws reConnect:^&#123; NSLog(@&quot;重连成功，继续发送刚刚的数据&quot;);[ws.socket send:data]; &#125;]; &#125; &#125; else &#123; NSLog(@&quot;没网络，发送失败，一旦断网 socket 会被我设置 nil 的&quot;);NSLog(@&quot;其实最好是发送前判断一下网络状态比较好，我写的有点晦涩，socket==nil来表示断网&quot;); &#125; &#125;);&#125; 7.心跳机制心跳机制就不难了，开个定时器，问下后台要每隔多少秒发送一次心跳请求就好了。然后注意，断网了或者socket断开的时候把心跳关一下，省资源，不然都断网了，还在循环发心跳，浪费CPU和电量。 终于接完websocket了，下班回家压压惊。我第一次用，其实不难，就是考虑的情况比较多，整个逻辑有点多，主要代码就是上面那些了，其他不重要的代码我就不复制粘贴上来了。","categories":[{"name":"移动端","slug":"移动端","permalink":"https://yidejia.github.io/categories/移动端/"}],"tags":[{"name":"曹堃","slug":"曹堃","permalink":"https://yidejia.github.io/tags/曹堃/"},{"name":"iOS","slug":"iOS","permalink":"https://yidejia.github.io/tags/iOS/"},{"name":"websocket","slug":"websocket","permalink":"https://yidejia.github.io/tags/websocket/"}],"keywords":[{"name":"移动端","slug":"移动端","permalink":"https://yidejia.github.io/categories/移动端/"}]},{"title":"Hexo + GitHub 搭建属于个人或团队的技术博客","slug":"Hexo + GitHub 搭建属于个人或团队的技术博客","date":"2016-11-02T09:23:55.000Z","updated":"2016-11-04T07:01:10.000Z","comments":true,"path":"2016/11/02/Hexo + GitHub 搭建属于个人或团队的技术博客/","link":"","permalink":"https://yidejia.github.io/2016/11/02/Hexo + GitHub 搭建属于个人或团队的技术博客/","excerpt":"","text":"现在很多个人或团队都有写博客的习惯，有的会选择将博客发表到如 CSDN、简书等比较受欢迎的地方，毕竟那里聚集了从菜鸟到大神的各类人才，来学习的和来吐槽的都有。本人就是喜欢热闹点的地方😬。不过今天不是介绍怎样将博文发表到这些地方，而是介绍如何使用 Hexo + GitHub 来搭建一个属于个人或团队的技术博客（从某种程度上也能提升逼格）。当然写博客最重要的还是抱着一种技术沉淀和积累的心态，将自己的所见、所闻、所感分享给大家。对于团队来说，也在一定程度上向外界传递当前团队的技术研发方向，招纳贤士，吸引人才嘛。 虽然这类文章现在满大街都是，但我觉得还是有必要将这两天的搭建过程给记下来，这其中包含了一些细节需要注意的。以下操作都是基于 Mac 系统，其他平台的请另行查阅。同时建议即将动手实战的朋友先通读本文，有些细节可能需要你提前注意的。最后，请自配翻墙工具。 一、准备环境Hexo 的安装需要依赖 Node.js，而对博客的管理我们选择 Git，所以我们要提前准备这两个环境。 安装 Git使用 brew 来安装 Git： brew install git 安装 Node.js首先我们需要通过 cURL 来安装 nvm： $ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.32.1/install.sh | bash 安装完成后，重新启动终端然后执行如下命令来安装 Node.js： nvm install stable 安装 Hexo经过上述步骤后，最后使用 npm 来安装 Hexo： npm install -g hexo-cli。 二、搭建博客既然我们使用 Hexo 来搭建博客，那势必要熟悉一下 Hexo 的几个常用语法： 1、首先选择一个目录，如/Users/zxq/Document/Blog 作为我们存储博客文件的目录，命令行切换到该目录下，然后执行： hexo init 2、初始化完成后，我们还需要执行下面命令来安装一些依赖： npm install 现在你的目录结构看起来应该是这样的： 因为我后面还装了一些插件，所以可能会多出 node_modules 这个目录，db.json 就是一个数据文件，部署运行后会自动生成。 到这里，博客的基础框架就搭建完成了，接下来我们就来部署一下，看看最终的显示效果。如果没特别提示的，下面的命令都在本地博客的根目录下操作。依次执行: hexo clean、hexo generate、hexo server。当运行 hexo server 后，命令行中会提示你访问 http://localhost:4000，打开浏览器看是否能正常访问。如果失败则需要在命令行窗口中查看失败日志。 简单说一下上面三个命令具体是执行哪些任务： hexo clean: 清除 hexo 生成的静态文件，由于 hexo 是一个博客框架，会将你编写的 Markdown 文件转换成相应的 HTML 文件，执行这个命令就可以删除系统为你生成的这些静态文件。 hexo generate: 通过上面的命令你也许能猜到这个命令的用意了，就是帮你生成静态文件的。 hexo server: 本地部署，这样你就能直接在浏览器上通过 http://localhost:4000 访问你的博客了。 其实上面命令还有对应的快捷方式，这个留给各位朋友自己摸索了。 三、编写博文博客搭建完后，接下来就要靠各位日后的辛勤耕耘和乐于分享了。我们可以直接通过 hexo new Hello_World 命令来创建博文，这种方式默认会将博文放置到博客根目录下的 source/_post 目录中。你也可以选择到该目录下创建 Markdown 文件。当编写好博文后，通过上面描述的三条命令 clean，generate，server 重新部署一下就可以了。 当然，编写博文的方式还远远不止这些， 详情请查看 Hexo 官方文档。 四、GitHub 远程部署博客完成上面三个步骤后，你现在的博客仅仅是部署在你本地电脑上，只允许同一局域网进行访问，当然如果你有自己的服务器那就另当别论了。下面将介绍如何将你的博客部署到全球最大的程序员交友网站 GitHub。在这里我先申明一下，你既然都看到了这篇文章，那至少你对 GitHub 有所了解了，起码也得有个账号吧。 接下来我们登录 GitHub，新建一个仓库。注意，这个仓库名称必须是：GitHub 的账户昵称 + “.github.io”，如 因为我已经创建过了，所以会提示仓库已存在。你要注意的就是这个仓库名称格式，这个仓库名称格式，这个仓库名称格式，重要事情说三遍。只有这种格式的仓库 GitHub 才能识别。 这里要唠叨两句，很重要的，不要走神。在 GitHub 上每创建一个仓库，那么该仓库默认会指定 master 分支作为其主要分支。博客仓库（xxx.github.io）也是一样的，GitHub 会默认部署 master 分支上的静态文件（前面说过静态文件是 hexo 将博客源文件转化后的产物）。你若不小删除了这些静态文件我们还可以通过源文件再生成，但如果你不小心删除了博客源文件，那可能就麻烦了。所以我们要借助 Git 来管理我们整个博客的源文件了。可能有些人会想再创建一个新的仓库来管理这些源文件，当然这样也没有错，但还有另一种方式，那就是在博客仓库中再创建一个分支，如下图： 注意：hexo 生成的静态文件和博客源文件最好不要混在一起管理，这也是为什么需要两个分支的原因，一个管理静态文件，一个管理博客源文件。 因为我们大多数时间是花在写博客上，所以选择用 hexo 分支来管理我们的博客源文件，而 master 分支用于管理静态文件。在 hexo 分支上的操作跟普通操作 git 一样，至于怎么更新 master 分支上的静态文件后面会揭晓。 不过现在博客仓库的默认分支还是 master，这里我们要将 hexo 修改为默认分支，方便Git 今后操作源文件。操作如下： 当执行完上述流程后，打开本地博客根目录下的 _config.xml 配置文件，索引 Deployment 然后替换为下面的信息： 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: https://github.com/xxx/xxx.github.io (你的博客仓库地址） branch: master 保存后接着执行 npm install hexo-deployer-git --save，只有执行该命令我们才能将待会生成的静态文件推送到远程仓库中。 好了，该准备的也准备得差不多了。提醒一下，推送静态文件到远程 master 分支不再是什么 git push，而是这一系列的命令：hexo clean，hexo generate，hexo deploy。细心的朋友可能发现最后一个命令不再是上面提到的 hexo server，而是hexo deploy，相当于将本地的这些静态文件部署推送到远程的 master 分支上。这一切的前提是上面配置文件中的仓库地址要填写正确。 现在就可以到 GitHub 网站上查看博客仓库的 master 分支上是否有那些静态文件，诸如 html，js 和 css 等等。如果正常的话，那么过一会你就能通过 https://xxx.github.io（比如 https://anenn.github.io） 这个地址直接访问你的博客，因为 GitHub 已经为你完成部署工作了。 四、博客源文件管理完成上述流程后，那接下来的也就小菜一碟了。我们要用 Git 来管理我们的文件，基本流程就是： 命令行切换到本地博客根目录下，执行 git init，表明我们要用 Git 来管理该目录下的所有文件； 然后将本地仓库跟远程仓库进行绑定，执行 git remote add origin xxx(远程仓库地址，如 https://github.com/anenn/anenn.github.io)； 切换分支到 hexo，执行 git checkout -b hexo； 将源文件先添加到本地仓库中，在此之前我建议先执行一下 hexo clean，将系统为我们生成的静态文件删除，因为它不属于我们的博客源文件，然后再执行 git add . | git commit -m “xxx”； 最后就是同步了，执行 git pull | git push 记住，今后一切一切的操作都在 hexo 分支上执行，不要再跑去 master 分支上瞎闹，搞不好会搞挂博客的。 五、总结上面流程下来不出意外的话应该是可以正常运行的，如果有什么问题的请留言反馈。最后想对搭团队博客的朋友说，如果团队成员有写博客的习惯，若让他们每个人在自己电脑上都搞这一套，不用想，肯定不会怎么受欢迎的。所以，可以接受的方式就是让他们 clone 下团队博客的源代码，然后让他们切换到 hexo 分支上去编写博文，最后同步上去再由自动化脚本去执行部署操作。对于他们来说，整个部署流程透明化，他们仅需关心的就是如何写好每一篇博文。 参考文献： Hexo 官方文档 Hexo利用Github分支在不同电脑上写博客 在不同的电脑维护Hexo和写作","categories":[{"name":"移动端","slug":"移动端","permalink":"https://yidejia.github.io/categories/移动端/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://yidejia.github.io/tags/Hexo/"},{"name":"GitHub","slug":"GitHub","permalink":"https://yidejia.github.io/tags/GitHub/"},{"name":"Blog 博客","slug":"Blog-博客","permalink":"https://yidejia.github.io/tags/Blog-博客/"}],"keywords":[{"name":"移动端","slug":"移动端","permalink":"https://yidejia.github.io/categories/移动端/"}]},{"title":"Jenkins+GitLab+Android+iOS+Sonar搭建持续集成环境","slug":"Jenkins-搭建","date":"2016-11-02T06:12:55.000Z","updated":"2016-11-04T07:01:10.000Z","comments":true,"path":"2016/11/02/Jenkins-搭建/","link":"","permalink":"https://yidejia.github.io/2016/11/02/Jenkins-搭建/","excerpt":"","text":"持续集成是敏捷开发的重要一环,它具备以下优点: 减少并降低软件开发中的风险 将重复性工作自动化，让开发人员更专注于代码 在任何时间、任何地点生成可部署的软件 随着人员以及项目的增加,以上这些就变得尤为重要.所以我们也在恰当的时机把它引入进来. 而市面上持续集成系统琳琅满目,有Jenkins,Travis,Circleci,Bitrise,Flow.ci 我们该如何选择,那就参考大数据,朝内还是用百度指数,目前只收录Jenkins和Travis. Jenkins:蓝色 Travis:绿色 Jenkins更为成熟，它是框架式的，大部分功能通过插件的方式来实现，可扩展性非常高. 废话少说,直接来撸一撸! 下载Android SDK 下载Jenkins 安装 通过HomreBrew安装启动和停止jenkins服务: brew install jenkins brew tap homebrew/services Start Jenkins: sudo launchctl load /Library/LaunchDaemons/org.jenkins-ci.plist Stop Jenkins: sudo launchctl unload /Library/LaunchDaemons/org.jenkins-ci.plist 开机启动 Run at boot: /Library/LaunchDaemons 可以在这里修改jenkins相关信息 Run at login: /Users/Lavare/Library/LaunchAgents 通过pkg文件安装的可以通过 java命令启动: java -jar /Applications/Jenkins/jenkins.war Jenkins安装配置各种插件:Git —- GitLab —- Gitlab Authentication plugin (Git授权插件) Environment Injector Plugin (环境变量注入,目前用于获取gitLog,并传递给Fir.im上传信息) Email Extension (邮件扩展插件,打包完成后邮件通知各人员) Fir Plugin (Fir.im上传插件,apk/ipa 分发渠道) Bearychat Plugin (上传到Bearychat插件,同于通知) Gradle Plugin (Android 构建插件) Xcode integration (iOS构建插件) Keychains and Provisioning Profiles Management (iOS证书配置插件) Sonar:代码质量管理平台,也是通过安装各种插件来扩展代码检测功能 1.糟糕的复杂度分布 2.重复 3.缺乏单元测试 4.没有代码标准 5.没有足够的或者过多的注释 6.潜在的bug 7.糟糕的设计 在系统管理界面配置-&gt;系统设置 GitLab配置,使用Api Token验证 Bearychat配置,方便后期构建成功后通知到相应群组 Team Subdomain: 在 https://ydj.bearychat.com 中，如yjd便是团队的 subdomain Integration Token: 在 BearyChat 中的 Jenkins 机器人的 hook 地址中， 最后的部分便是 token。 Channel: 讨论组名称，如果指定的话，可以将 Jenkins 通知推送到该讨论组 Build Server URL: 团队的 Jenkins 服务器所在的地址，用于构建 Jenkins 通知中的链接等信息 Test Connection: 在填写上面的相关信息后，可以测试下是否配置成功 配置Sonar代码质量管理服务器 在Global Tool Config配置jdk,git 项目配置新建项目,使用自有构建模式 指定工作目录,和保持构建的天数,及最大个数,自定义目录 注意: 如果使用自定义工作空间,要考虑目录对当前是否有写入的权限, 源码管理使用http地址,也可以使用ssh要配key较麻烦 构建触发器,配置gitlab的webhook,有push变化则自动构建打包,指定对某一个分支有效: 周期性触发器: Build periodically指周期性构建（Provides a cron-like feature to periodically execute this project.） Poll SCM指周期性扫描远程git repository，当有变化时进行构建（Configure Jenkins to poll changes in SCM.） 日期定义 Cron表达式字符串的格式为“分 小时 日 月 星期 年”，其中“年”是可选的，其余5个字段是必须的。 区别（1）没有秒 （2）星期的取值范围是0-6（SUN-SAT） 字段取值范围通配符分0-59 / , -时0-59 / , -日1-31 / , - ? L W月1-12 or JAN-DEC / , -星期0-6 or SUN-SAT / , - ? L #年1970–2099 / , - 例子: /5 * // 每5分钟 H/5 // 每5分钟 推荐 5 // 每小时的第5分钟 0 8 * // 每天8点 0 16,18,20,22 * // 每天的16点、18点、20点、22点 0 1,18 * // 每天的1点和18点 03 09 1-5 // 工作日（周日到周五）的9点3分 59 23 1-5 或者 @midnight // 工作日（周日到周五）的9点3分 0 20 1-5 H 20 1-5 周一到周五的每晚8点自动构建 自定义环境变量获取Git Log 构建触发器配置完成后,我们还可以通过Environment Injector Plugin(环境变量注入插件),目前用于获取gitLog,并传递给Fir.im上传信息). 要先在Properties File Path 路径下创建一个对应的文件,否则改插件会报错找不到文件,名字可以自定义,但是要和Script Content的脚本内容中done&gt; 后面的文件及路径一致. 我这里用于测试后期,只需要显示昨天Git提交的信息: GIT_CHANGE_LOG=$(git log –after=”yesterday” –pretty=format:”%s”) echo “GIT_CHANGE_LOG=$(git log –after=”yesterday” –pretty=format:”%s” | while read line do echo $line\\\\\\\\n | tr -d \\n done)” ${WORKSPACE}/gitLogFile.properties 关于Git log的高级用法可以参考以下两篇文章: 博客园-Git log高级用法 Github-Git log 高级用法 在构建中配置刚刚的文件路径,用户读取里面的环境变量打 然后就可以在Fir插件上使用刚刚设置的环境变量${GIT_CHANGE_LOG} 构建分为Android和iOS构建,放在后面讲,先讲公共流程 构建期还可以通过Sonar来进行代码质量检查,配置源码路径,支持java,oc,swift,php,javascript sonar.projectKey=xxx_Android_Key sonar.projectName=xxx_Android_Name sonar.projectVersion=$BUILD_NUMBER sonar.sourceEncoding=UTF-8 sonar.sources=/Users/jz_mac_mini/xxx/xxx/app/src/main 静态代码目录(必选) sonar.java.libraries=/Users/jz_mac_mini/xxx/xxx/app/libs/ 第三方库目录(必选) sonar.java.binaries=/Users/jz_mac_mini/xxx/xxx/app/build/intermediates/classes/production/ 编译后的代码目录(必选) 可以通过Sonar的后台查看代码分析 构建后使用Fir.im发布,先安装ruby, $ gem sources –remove https://rubygems.org/ $ gem sources -a https://ruby.taobao.org/ $ gem sources -l CURRENT SOURCES https://ruby.taobao.org # 请确保只有 ruby.taobao.org, 如果有其他的源, 请 remove 掉 Mac OS X 10.11 以后的版本, 由于10.11引入了 rootless , 无法直接安装 fir-cli, 有以下三种解决办法: 使用 Homebrew 及 RVM 安装 Ruby, 再安装 fir-cli(推荐) Install Homebrew:$ ruby -e “$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)” Install RVM:$ \\curl -sSL https://get.rvm.io | bash -s stable –ruby $ gem install fir-cli 然后再通过插件配置Fir.im的账号,以及提交的fir的信息 jenkins的build版本为: $BUILD_NUMBER git的提交版本 号 为 : $GIT_COMMIT 可以通过bearychat插件来配置通知群组,在项目中配置 可以配置邮件通知,使用插件来配置email-ext-plugin,可以定制发送的内容, 先配置smtp服务器 然后指定发给哪些邮箱地址,以及定制发送的内容 也可以使用自带的邮件通知,要先制定系统管理员邮件地址 然后再配置邮件服务器smtp Android端构建配置 Android SDK配置 gradle可以指定本地的路径,也可以使用在线版本自动安装 构建,可以通过Tasks来指定任务 iOS端构建配置 目前我们使用的是Xcode默认配置打包,不用jenkins上配置的证书及PP文件.有几个关键点要注意的. 首先要在Xcode把项目中Projec和Target的Code Signing 设置为iOS Developer,以及把PP设置为Automatic. 然后在Product-&gt;Scheme-&gt;Manage Schemes 把项目设置为Shared,第三方库的不用设置 系统管理-&gt;找到Keychain and Provisioning Profiles Management 点击选择文件从本地选取Keychain,路径为:/Users/用户名/Library/Keychains/login.keychain 这里我们目前的做法是只配置login.keychain,然后jenkins的机子上安装Code Signing证书,再在xcode项目上fix issue,就能够为我们自动生成一个PP文件,名为-iOS Team Provisioning Profiles : xxxx, 而且当我们在开发者中心更新设备列表的时候,此PP文件是会自动加入的. 针对CocoaPods设置 如果项目是使用CocoaPods来管理的,还要针对xcworkspace进行build的话,还要额外进行写设置 如果构建是出现编码错误的可以在~/.bash_profile文件加上一句 export LC_ALL=”en_US.UTF-8” Xcode构建前,先用shell跑一遍pod install,我这里会出现pod: command not found 的错误,所以要在前面加上一句 #!/bin/bash -l pod install –verbose –no-repo-update 配置Workspace,红色的地方可以填上target名称,此处参考了章华龙的文章. 配置Workspace 非CocoaPods设置 配置Xcode 这里可以填入keychain来解锁 整个构建环境完成. 后期我们打算优化Sonar的检测分析,以及配置单元测试,UI测试,条件测试覆盖率等,继续往持续交付,持续部署的路上走! Keep Going!","categories":[{"name":"移动端","slug":"移动端","permalink":"https://yidejia.github.io/categories/移动端/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://yidejia.github.io/tags/Jenkins/"}],"keywords":[{"name":"移动端","slug":"移动端","permalink":"https://yidejia.github.io/categories/移动端/"}]}]}